{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical assignment\n",
    "\n",
    "The Microsoft Research Sentence Completion Challenge (Zweig and Burges, 2011) requires a system to\n",
    "be able to predict which is the most likely word (from a set of 5 possibilities) to complete a sentence. In\n",
    "the labs you have evaluated using unigram and bigram models. In this assignment you are expected to\n",
    "investigate at least 2 extensions or alternative approaches to making predictions. Your solution does\n",
    "not need to be novel. You might choose to investigate 2 of the following approaches or 1 of the following\n",
    "approaches and 1 of your own devising.\n",
    "\n",
    "•Tri-gram (or even quadrigram) models\n",
    "•Word similarity methods e.g., using Googlenews vectors or WordNet?\n",
    "•Combining n-gram methods with word similarity methods e.g., distributional smoothing?\n",
    "•Using a neural language model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import os,random,math\n",
    "import sys\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "\n",
    "training_dir=\"D:/Documents/Computer Science/Year 3/Semester Two/ANLE/lab2resources/lab2resources\"+\"/sentence-completion/Holmes_Training_Data/\"\n",
    "#testing_dir=\"D:/Documents/Computer Science/Year 3/Semester Two/ANLE/lab2resources/lab2resources/sentence-completion/testing_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by calling in needed libraries and setting the directories of data. We next want to read the data and format it correctly.\n",
    "\n",
    "The files are split between training and testing data from the holmes training data set. We then gather every line in the file within two large string array for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 522 files in the training directory: D:/Documents/Computer Science/Year 3/Semester Two/ANLE/lab2resources/lab2resources/sentence-completion/Holmes_Training_Data\n",
      "AESOP11.TXT TCHMS10.TXT\n",
      "[' the project gutenberg edition of at the back of the north wind please take a look at the important information in this header', ' we encourage you to keep this file on your own disk, keeping an electronic path open for the next readers', ' do not remove this', '  **welcome to the world of free plain vanilla electronic texts** **etexts readable by both humans and by computers, since 1971** *these etexts prepared by hundreds of volunteers and donations* information on contacting project gutenberg to get etexts, and further information is included below', ' we need your donations', '  at the back of the north wind, by george macdonald march, 1995 [etext #225]  proofed by martin ward', ' if you find an error in this text, please contact martin ward (martin', 'ward@durham', 'ac', 'uk)  **the project gutenberg etext of at the back of the north wind** ******this file should be named nwind10'] ['**welcome to the world of free plain vanilla electronic texts** **etexts readable by both humans and by computers, since 1971** *these etexts prepared by hundreds of volunteers and donations* information on contacting project gutenberg to get etexts, and further information is included below', ' we need your donations', '  july, 1993 [etext #74]  originally a june release of wiretap', ' tom sawyer, by mark twain, in honor of the mississippi floods', '', ' the entire book as originally published by the internet wiretap follows this header', ' only the headers have been changed, later project gutenberg will release an edition with the hyphenations removed for easier searching, and with two spaces between every sentence and paragraph for easier reading', ' [sawyr11', 'txt] this etext has been copyright cleared by project gutenberg with the cooperation of internet wiretap and tom dell who should get all the credit for this edition, and who are an inspiration for the entire etext community', ' it has been a pleasure to begin work with tom dell and internet wiretap']\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR=os.path.dirname(training_dir) #this needs to be the parent directory for the training corpus\n",
    "def get_training_testing(training_dir=TRAINING_DIR,split=0.5):\n",
    "    filenames=os.listdir(training_dir)\n",
    "    n=len(filenames)\n",
    "    print(\"There are {} files in the training directory: {}\".format(n,training_dir))\n",
    "    #random.seed(53) #if you want the same random split every time\n",
    "    random.shuffle(filenames)\n",
    "    index=int(n*split)\n",
    "    return(filenames[:index],filenames[index:])\n",
    "\n",
    "def readWords(files):\n",
    "    training=[]\n",
    "    for afile in files: #look through each file\n",
    "                #print(\"Processing {}\".format(afile))\n",
    "                try:\n",
    "                    sent=\"\"\n",
    "                    with open(os.path.join(training_dir,afile)) as instream: #get each line and preprocess\n",
    "                        for line in instream:\n",
    "                            line=line.lower()\n",
    "                            line=line.rstrip()\n",
    "                            sent+=line+\" \" #gather each line in the array\n",
    "                    \n",
    "                except UnicodeDecodeError:\n",
    "                    print(\"UnicodeDecodeError processing {}: ignoring file\".format(afile))\n",
    "                except PermissionError:\n",
    "                    print(\"denied\")\n",
    "    sent=sent.replace(\"?\",\".\").replace(\"!\",\".\").replace(\"  \",\" \")\n",
    "    training=sent.split(\".\") #get array of sentences\n",
    "    try: training.remove(\" \")  #remove spaces\n",
    "    except ValueError: pass\n",
    "    try: training.remove(' m') #remove random characters\n",
    "    except ValueError: pass\n",
    "    return training\n",
    "train,test=get_training_testing() #get the data\n",
    "\n",
    "print(train[0],test[0])\n",
    "\n",
    "train_words=readWords(train) #get the train sentences\n",
    "test_words=readWords(test) #get the test sentences\n",
    "print(train_words[0:10],test_words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing techniques on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def get_word_list(train):\n",
    "    dict={}\n",
    "    for sent in train:\n",
    "        for word in sent.split():\n",
    "            dict[word]=0\n",
    "    return list(dict.keys()) #list of unique words return\n",
    "def convert_to_vector(words):\n",
    "    oov_token = \"<OOV>\"\n",
    "    tokenizer = Tokenizer(num_words=len(words), oov_token=oov_token)\n",
    "    tokenizer.fit_on_texts(words)\n",
    "    #word_index = tokenizer.word_index\n",
    "    sequences = tokenizer.texts_to_sequences(words)\n",
    "    return list(pad_sequences(sequences, truncating='post', maxlen=4))\n",
    "def count_freq(train):\n",
    "    for sent in train:\n",
    "        pass\n",
    "words_train=get_word_list(train_words)\n",
    "x=convert_to_vector(words_train)\n",
    "\n",
    "def get_label_as_data(labels):\n",
    "    x=len(labels) #get the size of the array\n",
    "    arr=np.zeros((x)) #create an array of empty\n",
    "    lab=[]\n",
    "    for i in range(x):\n",
    "        a=np.copy(arr)\n",
    "        a[i]=1\n",
    "        lab.append(a)\n",
    "    return np.array(lab)\n",
    "INP_SIZE=len(x[0])\n",
    "\n",
    "x[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the first model\n",
    "\n",
    "A recurrent neural network is a good choice for this sort of task as the architecture makes it well suited to sequencing. This approach is taken with stochastic gradient descsent as stated in the research paper 'Character-Aware Neural Language Models'.\n",
    "\n",
    "The second approach used a feed-forward network where the vector as input and vector prediction as output. It encountered problems where the gradient optimization would grow infinitely smaller and eventually be an unrecognized value. Sigmoid was the only activation function that prevented this, however would force values between 0 and 1 resulting in incorrect predictions for a population of training data. \n",
    "\n",
    "The next model used labeled representation to represent the output, and labeled representation of the input. This approach improved the accuracy dramatically to 90-100% on the training set. A word, and an end word could be picked and trained, additionally if multiple words are related they can be selected. It takes a while to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dexter Shepherd\\AppData\\Local\\Temp\\ipykernel_4696\\1446256722.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(y,requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.01\n",
      "Testing network @ epoch 0\n",
      "Error: 7.459685790006551\n",
      "Accuracy 1.0\n",
      "Testing network @ epoch 500\n",
      "Error: 1.1057915699413832\n",
      "Accuracy 1.0\n",
      "Testing network @ epoch 1000\n",
      "Error: 1.1189537653001844\n",
      "Accuracy 1.0\n",
      "Testing network @ epoch 1500\n",
      "Error: 1.121795774679017\n",
      "the the\n",
      "project project\n",
      "gutenberg gutenberg\n",
      "edition edition\n",
      "of of\n",
      "at at\n",
      "back back\n",
      "north north\n",
      "wind wind\n",
      "please please\n",
      "take take\n",
      "a a\n",
      "look look\n",
      "important important\n",
      "information information\n",
      "in in\n",
      "this this\n",
      "header header\n",
      "we we\n",
      "encourage encourage\n",
      "you you\n",
      "to to\n",
      "keep keep\n",
      "file file\n",
      "on on\n",
      "your your\n",
      "own own\n",
      "disk, disk,\n",
      "keeping keeping\n",
      "an an\n",
      "electronic electronic\n",
      "path path\n",
      "open open\n",
      "for for\n",
      "next next\n",
      "readers readers\n",
      "do do\n",
      "not not\n",
      "remove remove\n",
      "**welcome **welcome\n",
      "world world\n",
      "free free\n",
      "plain plain\n",
      "vanilla vanilla\n",
      "texts** texts**\n",
      "**etexts **etexts\n",
      "readable readable\n",
      "by by\n",
      "both both\n",
      "humans humans\n",
      "and and\n",
      "computers, computers,\n",
      "since since\n",
      "1971** 1971**\n",
      "*these *these\n",
      "etexts etexts\n",
      "prepared prepared\n",
      "hundreds hundreds\n",
      "volunteers volunteers\n",
      "donations* donations*\n",
      "contacting contacting\n",
      "get get\n",
      "etexts, etexts,\n",
      "further further\n",
      "is is\n",
      "included included\n",
      "below below\n",
      "need need\n",
      "donations donations\n",
      "wind, wind,\n",
      "george george\n",
      "macdonald macdonald\n",
      "march, march,\n",
      "1995 1995\n",
      "[etext [etext\n",
      "#225] #225]\n",
      "proofed proofed\n",
      "martin martin\n",
      "ward ward\n",
      "if if\n",
      "find find\n",
      "error error\n",
      "text, text,\n",
      "contact contact\n",
      "(martin (martin\n",
      "ward@durham ward@durham\n",
      "ac ac\n",
      "uk) uk)\n",
      "**the **the\n",
      "etext etext\n",
      "wind** wind**\n",
      "******this ******this\n",
      "should should\n",
      "be be\n",
      "named named\n",
      "nwind10 nwind10\n",
      "txt txt\n",
      "or or\n",
      "zip******** zip********\n",
      "corrected corrected\n",
      "End Accuracy 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FNN:\n",
    "    def __init__(self,words,inp=4,hid=10,out=4,m=0,std=0.2): #feed forward neural network\n",
    "        \n",
    "        self.inp = torch.nn.Parameter(torch.normal(m,std,(inp, hid))) #output hidden\n",
    "        self.h0 = torch.nn.Parameter(torch.normal(m,std,(hid, hid))) #output hidden\n",
    "        #self.h1 = torch.nn.Parameter(torch.normal(m,std,(hid, hid))) #output hidden\n",
    "        self.h2 = torch.nn.Parameter(torch.normal(m,std,(hid, out))) #output hidden\n",
    "        self.words={}\n",
    "        #vecs=convert_to_vector(words)\n",
    "        vecs=get_label_as_data(words)\n",
    "        for i,word in enumerate(words): #create dict\n",
    "            self.words[word]=vecs[i]\n",
    "    def forward(self,item): #pass through network\n",
    "        item=item[:,np.newaxis]\n",
    "        x=torch.tensor(item).float()\n",
    "        x=(torch.mm(x.T, self.inp)) #torch.sigmoid\n",
    "        x=(torch.mm(x, self.h0))\n",
    "        #x=torch.sigmoid(torch.mm(x, self.h1))\n",
    "        x=(torch.mm(x, self.h2))\n",
    "        return x[0]\n",
    "    def train(self,words,targets,epochs=400):\n",
    "        print(\"Training...\")\n",
    "        #get each word in index\n",
    "        \n",
    "        #get words in relation of neigbours\n",
    "        #train word to next word\n",
    "        optimizer = torch.optim.SGD((self.inp,self.h0,self.h2), lr=0.20) #, momentum=0.9\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        for epoch in range(epochs):\n",
    "            error=0\n",
    "            correct=0\n",
    "            for i in range(len(words)):\n",
    "                X=self.words.get(words[i],np.array([0,0,0,0]))\n",
    "                y=torch.tensor(targets[i]).double()\n",
    "                y=torch.tensor(y,requires_grad=True)\n",
    "               \n",
    "                pred=self.forward(X)\n",
    "                #X=torch.tensor(torch.tensor(X).double(),requires_grad=True)\n",
    "                optimizer.zero_grad()\n",
    "                loss = loss_fn(pred, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()  \n",
    "                if np.argmax(pred.data.numpy())==i:\n",
    "                    correct+=1\n",
    "                error+=sum(abs(y.data.numpy() - pred.data.numpy()))/4\n",
    "            \n",
    "            if epoch %500 == 0:\n",
    "                #print(loss,torch.round(pred),y)\n",
    "                #print(sum((y.data.numpy() - pred.data.numpy()))/4)\n",
    "                print(\"Accuracy\",correct/len(words))\n",
    "                print(f\"Testing network @ epoch {epoch}\")\n",
    "                print(\"Error:\",error/len(words))\n",
    "        \n",
    "    def getWordThing(self,word):\n",
    "        return self.words.get(word,np.array([0,0,0,0]))\n",
    "    def get_action(self,word):\n",
    "        vec=self.words.get(word,np.array([0,0,0,0])) #give default\n",
    "        word_vec = self.forward(vec).data.numpy() #gather vector\n",
    "        ind=np.argmax(word_vec)\n",
    "        #print(word,word_vec,ind)\n",
    "        return list(self.words.keys())[ind]\n",
    "    def getWord(self,word_vec):\n",
    "        w=\"None\"\n",
    "        for key in self.words:\n",
    "            #print(self.words[key],word_vec)\n",
    "            if np.array_equal(self.words[key],word_vec): #loop through\n",
    "                w=key\n",
    "        return w\n",
    "    def get_accuracy(self,words,labels): #get accuracy\n",
    "        acc=0\n",
    "        for word,label in zip(words,labels): #zip them together\n",
    "            act=self.get_action(word) #get action from this word\n",
    "            #print(act,list(self.words.keys())[np.argmax(label)])\n",
    "            if act==list(self.words.keys())[np.argmax(label)]:\n",
    "                acc+=1\n",
    "        return acc/len(words) #return accuracy\n",
    "\n",
    "NUM_DATA=100\n",
    "words_train=get_word_list(train_words)[0:NUM_DATA]\n",
    "labels=get_label_as_data(words_train[0:NUM_DATA])\n",
    "netF=FNN(words_train,inp=len(words_train),hid=len(labels[0])//2,out=len(labels[0]))\n",
    "#print(netF.forward(x[0]))#\n",
    "#print(words_train[0:4],labels[0:4])\n",
    "netF.train(words_train[0:NUM_DATA],labels[0:NUM_DATA],epochs=1000)  \n",
    "print(\"End Accuracy\",netF.get_accuracy(words_train[0:NUM_DATA],labels[0:NUM_DATA])*100,\"%\")\n",
    "\n",
    "netF.getWordThing(words_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An attempt to make a feed forward neural network was placed in as there were issues with backpropagating the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the second model\n",
    "\n",
    "Using a cluster of n gram models we can predict likelihood of words based on different categories. The frequency of words are calculated in each unigram, bigram and trigram model. When a cluster prediction is made it finds the most likely and most frequent next word from the models. Each model by itself had a poor accuracy, which was improved by over 2% by using them as clustered. Weighting of importance is applied as n rises in the gram model, as words become rarer. This once again improved tha accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram accuracy 0.5137963843958135 %\n",
      "Bigram accuracy 0.5744586831639417 %\n",
      "Trigram accuracy 0.26434047052603754 %\n",
      "Cluster Accuracy: 5.3667831057478566 %\n"
     ]
    }
   ],
   "source": [
    "class n_gram:\n",
    "    def __init__(self,sentences,n):\n",
    "        self.n=n\n",
    "        self.sent=sentences\n",
    "        #begin \n",
    "        self.data={}\n",
    "        self.format()\n",
    "    def format(self):\n",
    "        for sentence in self.sent:\n",
    "            words=sentence.split()\n",
    "            develop_n = []\n",
    "            for k in range(len(words)): #gather each word \n",
    "                i=0\n",
    "                s=\"\"\n",
    "                while i+k<len(words) and i<self.n: #get in terms of word connection\n",
    "                    s+=words[k+i].replace(\",\",\"\").replace(\";\",\"\").replace(\"*\",\"\").replace(\"'\",\"\").replace(\"#\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")+\"-\"\n",
    "                    i+=1\n",
    "                develop_n.append(s[:-1]) #add connections\n",
    "            for i,cont in enumerate(develop_n): #loop through number in sentence\n",
    "                if i+self.n+1<len(words): #validate next word\n",
    "                    nextword=words[i+self.n].replace(\",\",\"\").replace(\";\",\"\").replace(\"*\",\"\").replace(\"'\",\"\").replace(\"#\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "                    self.data[cont]=self.data.get(cont,{})\n",
    "                    self.data[cont][nextword]=self.data[cont].get(nextword,0)+1 #count\n",
    "    def get_predict(self,phrase): #get a prediction of a word\n",
    "        phrase=phrase.replace(\" \",\"-\")\n",
    "        words=self.data.get(phrase,None)\n",
    "        if words==None: return \"no word found\"\n",
    "        return {k: v for k, v in sorted(words.items(), key=lambda item: item[1])} #get return\n",
    "    def get_accuracy(self,words):\n",
    "        c=0\n",
    "        a=0\n",
    "        for sent in words: #loop through the sentences\n",
    "            sent=sent.replace(\",\",\"\").replace(\";\",\"\").replace(\"*\",\"\").replace(\"'\",\"\").replace(\"#\",\"\").replace(\"[\",\"\").replace(\"]\",\"\") #validate\n",
    "            sent=sent.split()\n",
    "            if len(sent)-2-self.n>self.n:              \n",
    "                num=random.randint(self.n,len(sent)-2-self.n) #get idx point\n",
    "                phrase=sent[num-self.n:num]\n",
    "                s=\"\"\n",
    "                for i in range(self.n): s+=phrase[i]+\"-\"\n",
    "                c+=1\n",
    "                pred=self.get_predict(s[:-1])\n",
    "                #print(phrase,list(pred.keys())[0])\n",
    "                if pred!=\"no word found\" and list(pred.keys())[0]==sent[num+1]: a+= 1 #correct prediction\n",
    "        return a/c\n",
    "unigram=n_gram(train_words.copy(),1)\n",
    "print(\"Unigram accuracy\",unigram.get_accuracy(train_words)*100,\"%\")\n",
    "bigram=n_gram(train_words.copy(),2)\n",
    "print(\"Bigram accuracy\",bigram.get_accuracy(train_words)*100,\"%\")\n",
    "trigram=n_gram(train_words.copy(),3)\n",
    "print(\"Trigram accuracy\",trigram.get_accuracy(train_words)*100,\"%\")\n",
    "def most_common(lst):\n",
    "    cur_length = 0\n",
    "    max_length = 0\n",
    "    cur_i = 0\n",
    "    max_i = 0\n",
    "    cur_item = None\n",
    "    max_item = None\n",
    "    for i, item in sorted(enumerate(lst), key=lambda x: x[1]):\n",
    "        if cur_item is None or cur_item != item:\n",
    "            if cur_length > max_length or (cur_length == max_length and cur_i < max_i):\n",
    "                max_length = cur_length\n",
    "                max_i = cur_i\n",
    "                max_item = cur_item\n",
    "            cur_length = 1\n",
    "            cur_i = i\n",
    "            cur_item = item\n",
    "        else:\n",
    "            cur_length += 1\n",
    "    if cur_length > max_length or (cur_length == max_length and cur_i < max_i):\n",
    "        return cur_item\n",
    "    return max_item\n",
    "def clusterPredict(sentence,mod1,mod2,mod3):\n",
    "    firstLast,secondLast,thirdLast=sentence[-1],sentence[-2],sentence[-3]\n",
    "    preds1,preds2,preds3=[mod1.get_predict(firstLast),\n",
    "    mod2.get_predict(firstLast+\"-\"+secondLast),\n",
    "    mod3.get_predict(firstLast+\"-\"+secondLast+\"-\"+thirdLast)]\n",
    "    words=[]\n",
    "    multiplier=1\n",
    "    for dict in [preds1,preds2,preds3]: #loop through all predictions\n",
    "        if dict!=\"no word found\":\n",
    "            for key in dict:\n",
    "                for i in range(dict[key]*multiplier):\n",
    "                    words.append(key) #add multiple times if occurs multiple \n",
    "        multiplier+=1\n",
    "    return most_common(words) #get most common word in list\n",
    "acc=0\n",
    "num=len(train_words)\n",
    "for i in range(num):\n",
    "    sent=train_words[i].split()\n",
    "    if len(sent)>=4:\n",
    "        pred=clusterPredict(sent[0:-1],unigram,bigram,trigram)\n",
    "        if sent[-1]==pred: acc+=1\n",
    "print(\"Cluster Accuracy:\",acc/num *100,\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance\n",
    "\n",
    "Experimentation with the number of models within the cluster prediction takes place to experiment what the optimal clustering models are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 model\n",
      "2 model\n",
      "3 model\n",
      "4 model\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clusterPredictX(sentence,mods):\n",
    "    words=[sentence[-1],sentence[-2],sentence[-3],sentence[-4]]\n",
    "    preds=[]\n",
    "    for i,mod in enumerate(mods):\n",
    "        s=\"\"\n",
    "        for w in words:\n",
    "            s=w+\"-\"+s\n",
    "        preds.append(mod.get_predict(s[:-1]))\n",
    "    words=[]\n",
    "    multiplier=1\n",
    "    for dict in preds: #loop through all predictions\n",
    "        if dict!=\"no word found\":\n",
    "            for key in dict:\n",
    "                for i in range(dict[key]*multiplier):\n",
    "                    words.append(key) #add multiple times if occurs multiple \n",
    "        multiplier+=1\n",
    "    return most_common(words) #get most common word in list\n",
    "sentence=train_words[0].split()\n",
    "\n",
    "acc_=[]\n",
    "sizes=[]\n",
    "NUM = len(train_words)\n",
    "num_models=4\n",
    "for i in range(num_models): #get model sizes\n",
    "    print(str(i+1)+\" model\")\n",
    "    s=[]\n",
    "    a=[]\n",
    "    for word_set in range(100,601,500): #get sample sizes\n",
    "        unigram=n_gram(train_words.copy()[0:word_set],1)\n",
    "        bigram=n_gram(train_words.copy()[0:word_set],2)\n",
    "        trigram=n_gram(train_words.copy()[0:word_set],3)\n",
    "        quadgram=n_gram(train_words.copy()[0:word_set],4)\n",
    "        models=[unigram,bigram,trigram,quadgram]\n",
    "        mods=models[0:i+1] #get increasing size\n",
    "\n",
    "        acc=0\n",
    "        num=len(train_words[0:word_set])\n",
    "        for k in range(num): #loop through words\n",
    "            sent=train_words[k].split()\n",
    "            if len(sent)>=5:\n",
    "                pred=clusterPredictX(sent[0:-1],mods)\n",
    "                if sent[-1]==pred: acc+=1 \n",
    "        a.append(acc/num *100)\n",
    "        s.append(word_set)\n",
    "    acc_.append(a.copy())\n",
    "    sizes.append(s.copy())\n",
    "\n",
    "plt.title(\"Cluster model accuracy against size of data with different cluster sizes\")\n",
    "plt.plot(sizes[0],acc_[0],c=\"r\",label=\"One model cluster\")\n",
    "plt.plot(sizes[1],acc_[1],c=\"b\",label=\"Two model cluster\")\n",
    "plt.plot(sizes[2],acc_[2],c=\"g\",label=\"Three model cluster\")\n",
    "plt.plot(sizes[3],acc_[3],c=\"y\",label=\"Four model cluster\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.xlabel(\"Wordset size\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_[1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4dd024378a2eab6b61421bb2db15dae0e0d8b99b3e2b4f86d231a4685d0f22e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
